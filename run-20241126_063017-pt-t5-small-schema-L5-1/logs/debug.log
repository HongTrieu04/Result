2024-11-26 06:30:17,771 INFO    MainThread:58158 [wandb_setup.py:_flush():79] Current SDK version is 0.18.7
2024-11-26 06:30:17,771 INFO    MainThread:58158 [wandb_setup.py:_flush():79] Configure stats pid to 58158
2024-11-26 06:30:17,771 INFO    MainThread:58158 [wandb_setup.py:_flush():79] Loading settings from /root/.config/wandb/settings
2024-11-26 06:30:17,771 INFO    MainThread:58158 [wandb_setup.py:_flush():79] Loading settings from /root/SGD_NLG-main/wandb/settings
2024-11-26 06:30:17,771 INFO    MainThread:58158 [wandb_setup.py:_flush():79] Loading settings from environment variables: {}
2024-11-26 06:30:17,771 INFO    MainThread:58158 [wandb_setup.py:_flush():79] Applying setup settings: {'mode': None, '_disable_service': None}
2024-11-26 06:30:17,771 INFO    MainThread:58158 [wandb_setup.py:_flush():79] Inferring run settings from compute environment: {'program_relpath': 'train_model.py', 'program_abspath': '/root/SGD_NLG-main/train_model.py', 'program': '/root/SGD_NLG-main/train_model.py'}
2024-11-26 06:30:17,772 INFO    MainThread:58158 [wandb_setup.py:_flush():79] Applying login settings: {}
2024-11-26 06:30:17,772 INFO    MainThread:58158 [wandb_init.py:_log_setup():533] Logging user logs to ./wandb/run-20241126_063017-pt-t5-small-schema-L5-1/logs/debug.log
2024-11-26 06:30:17,772 INFO    MainThread:58158 [wandb_init.py:_log_setup():534] Logging internal logs to ./wandb/run-20241126_063017-pt-t5-small-schema-L5-1/logs/debug-internal.log
2024-11-26 06:30:17,772 INFO    MainThread:58158 [wandb_init.py:init():619] calling init triggers
2024-11-26 06:30:17,772 INFO    MainThread:58158 [wandb_init.py:init():626] wandb.init called with sweep_config: {}
config: {'ModelName': 'mlp-prefix-t5-small-SGD', 'ExpName': 'mlp-prefix-t5-small-schema-L5', 'VerName': 'pt-t5-small-schema-L5-1', 'WandbProject': 'bbyrne-nlg', 'Note': 'prefix t5-small for SGD, using schema guided SR', 'TokenizerInfo': {'tokenizer_class': 'T5TokenizerFast', 'tokenizer_name': 't5-small', 'tokenizer_alias': 'T5TokenizerFast'}, 'LightningModuleName': 'PrefixT5GenerationModel', 'LightningModuleParas': {'model_class': 'PT_T5Model', 'model_path': '/models/mlp-prefix-t5-small-SGD/logs/mlp-prefix-t5-small-schema-L5/pt-t5-small-schema-L5-1/checkpoints/epoch=0-step=10000.ckpt', 'optimizer': 'AdamW', 'optimizer_params': {'lr': 0.0001}, 'prefix_length': 5, 'hidden_dims': [512, 384]}, 'LightningDataModuleName': 'GEMSGD_DataModule', 'LightningDataModuleParas': {'batch_size': 8, 'tokenizer_name': 'T5TokenizerFast', 'force_process': False, 'save_cache': True, 'encode_args': {'padding': 'max_length', 'truncation': True}, 'linearizer_class': 'SGD_SchemaGuidedLinearizer', 'schema_paths': ['data/schemas/schema-train.json', 'data/schemas/schema-test.json', 'data/schemas/schema-dev.json'], 'template_dir': 'data/utterance_templates'}, 'TrainerParas': {'max_epochs': 2, 'val_check_interval': 10000, 'accelerator': 'gpu', 'devices': 1, 'default_root_dir': 'models/mlp-prefix-t5-small-SGD'}, 'ModelCheckpointParas': {'monitor': 'val_loss'}, 'TrainLoggerName': 'WandbLogger', 'TrainLoggerParas': {'project': 'bbyrne-nlg', 'name': 'mlp-prefix-t5-small-schema-L5', 'version': 'pt-t5-small-schema-L5-1'}, 'TestLoggerName': 'CSVLogger', 'TestLoggerParas': {'name': 'mlp-prefix-t5-small-schema-L5', 'version': 'pt-t5-small-schema-L5-1'}, 'LoadingParas': {'checkpoint_path': 'pt-t5-small-schema-L5-1/checkpoints/epoch=4-step=102491.ckpt', 'save_decode': True, 'decode_path': 'logs/mlp-prefix-t5-small-schema-L5/test-pt-t5-schema-L5', 'generate_params': {'max_new_tokens': 200, 'num_beams': 4, 'length_penalty': 0.6, 'early_stopping': True, 'bos_token_id': 0}}}
2024-11-26 06:30:17,772 INFO    MainThread:58158 [wandb_init.py:init():669] starting backend
2024-11-26 06:30:17,773 INFO    MainThread:58158 [wandb_init.py:init():673] sending inform_init request
2024-11-26 06:30:17,775 INFO    MainThread:58158 [backend.py:_multiprocessing_setup():104] multiprocessing start_methods=fork,spawn,forkserver, using: spawn
2024-11-26 06:30:17,776 INFO    MainThread:58158 [wandb_init.py:init():686] backend started and connected
2024-11-26 06:30:17,782 INFO    MainThread:58158 [wandb_init.py:init():781] updated telemetry
2024-11-26 06:30:17,791 INFO    MainThread:58158 [wandb_init.py:init():814] communicating run to backend with 90.0 second timeout
2024-11-26 06:30:18,668 INFO    MainThread:58158 [wandb_init.py:init():859] run resumed
2024-11-26 06:30:18,702 INFO    MainThread:58158 [wandb_init.py:init():867] starting run threads in backend
2024-11-26 06:30:18,896 INFO    MainThread:58158 [wandb_run.py:_console_start():2456] atexit reg
2024-11-26 06:30:18,896 INFO    MainThread:58158 [wandb_run.py:_redirect():2305] redirect: wrap_raw
2024-11-26 06:30:18,896 INFO    MainThread:58158 [wandb_run.py:_redirect():2370] Wrapping output streams.
2024-11-26 06:30:18,896 INFO    MainThread:58158 [wandb_run.py:_redirect():2395] Redirects installed.
2024-11-26 06:30:18,900 INFO    MainThread:58158 [wandb_init.py:init():911] run started, returning control to user process
2024-11-26 06:30:19,423 INFO    MainThread:58158 [wandb_run.py:_config_callback():1387] config_cb None None {'model_class': 'PT_T5Model', 'model_path': '/models/mlp-prefix-t5-small-SGD/logs/mlp-prefix-t5-small-schema-L5/pt-t5-small-schema-L5-1/checkpoints/epoch=0-step=10000.ckpt', 'tokenizer': None, 'optimizer': 'AdamW', 'optimizer_params': {'lr': 0.0001}, 'decode_path': 'default_test/', 'save_decode': False, 'generate_params': None, 'prefix_model_name': 'MLPPrefixModel', 't5_model_name': 't5-small', 'prefix_length': 5, 'hidden_dims': [512, 384], 'activation_fn_name': 'Tanh', 'prefix_dropout': 0.0}
